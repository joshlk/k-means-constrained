

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Welcome to k-means-constrained’s documentation! &mdash; k-means-constrained 0.0.2 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="#" class="icon icon-home" alt="Documentation Home"> k-means-constrained
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">Welcome to k-means-constrained’s documentation!</a></li>
</ul>
</div>
            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">k-means-constrained</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="#" class="icon icon-home"></a> &raquo;</li>
        
      <li>Welcome to k-means-constrained’s documentation!</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/index.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="welcome-to-k-means-constrained-s-documentation">
<h1>Welcome to k-means-constrained’s documentation!<a class="headerlink" href="#welcome-to-k-means-constrained-s-documentation" title="Permalink to this headline">¶</a></h1>
<p>The GitHub project can be found <a class="reference external" href="https://github.com/joshlk/k-means-constrained">here</a>.</p>
<p>To install k-means-constrained using pip:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">k</span><span class="o">-</span><span class="n">means</span><span class="o">-</span><span class="n">constrained</span>
</pre></div>
</div>
<p>API documentation:</p>
<span class="target" id="module-k_means_constrained"></span><dl class="py class">
<dt id="k_means_constrained.KMeansConstrained">
<em class="property">class </em><code class="sig-prename descclassname">k_means_constrained.</code><code class="sig-name descname">KMeansConstrained</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">n_clusters</span><span class="o">=</span><span class="default_value">8</span></em>, <em class="sig-param"><span class="n">size_min</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">size_max</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">init</span><span class="o">=</span><span class="default_value">'k-means++'</span></em>, <em class="sig-param"><span class="n">n_init</span><span class="o">=</span><span class="default_value">10</span></em>, <em class="sig-param"><span class="n">max_iter</span><span class="o">=</span><span class="default_value">300</span></em>, <em class="sig-param"><span class="n">tol</span><span class="o">=</span><span class="default_value">0.0001</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">random_state</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">copy_x</span><span class="o">=</span><span class="default_value">True</span></em>, <em class="sig-param"><span class="n">n_jobs</span><span class="o">=</span><span class="default_value">1</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/k_means_constrained/k_means_constrained_.html#KMeansConstrained"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#k_means_constrained.KMeansConstrained" title="Permalink to this definition">¶</a></dt>
<dd><p>K-Means clustering with minimum and maximum cluster size constraints</p>
<dl class="field-list">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl>
<dt><strong>n_clusters</strong><span class="classifier">int, optional, default: 8</span></dt><dd><p>The number of clusters to form as well as the number of
centroids to generate.</p>
</dd>
<dt><strong>size_min</strong><span class="classifier">int, optional, default: None</span></dt><dd><p>Constrain the label assignment so that each cluster has a minimum
size of size_min. If None, no constrains will be applied</p>
</dd>
<dt><strong>size_max</strong><span class="classifier">int, optional, default: None</span></dt><dd><p>Constrain the label assignment so that each cluster has a maximum
size of size_max. If None, no constrains will be applied</p>
</dd>
<dt><strong>init</strong><span class="classifier">{‘k-means++’, ‘random’ or an ndarray}</span></dt><dd><p>Method for initialization, defaults to ‘k-means++’:</p>
<p>‘k-means++’ : selects initial cluster centers for k-mean
clustering in a smart way to speed up convergence. See section
Notes in k_init for more details.</p>
<p>‘random’: choose k observations (rows) at random from data for
the initial centroids.</p>
<p>If an ndarray is passed, it should be of shape (n_clusters, n_features)
and gives the initial centers.</p>
</dd>
<dt><strong>n_init</strong><span class="classifier">int, default: 10</span></dt><dd><p>Number of times the k-means algorithm will be run with different
centroid seeds. The final results will be the best output of
n_init consecutive runs in terms of inertia.</p>
</dd>
<dt><strong>max_iter</strong><span class="classifier">int, default: 300</span></dt><dd><p>Maximum number of iterations of the k-means algorithm for a
single run.</p>
</dd>
<dt><strong>tol</strong><span class="classifier">float, default: 1e-4</span></dt><dd><p>Relative tolerance with regards to inertia to declare convergence</p>
</dd>
<dt><strong>verbose</strong><span class="classifier">int, default 0</span></dt><dd><p>Verbosity mode.</p>
</dd>
<dt><strong>random_state</strong><span class="classifier">int, RandomState instance or None, optional, default: None</span></dt><dd><p>If int, random_state is the seed used by the random number generator;
If RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used
by <cite>np.random</cite>.</p>
</dd>
<dt><strong>copy_x</strong><span class="classifier">boolean, default True</span></dt><dd><p>When pre-computing distances it is more numerically accurate to center
the data first.  If copy_x is True, then the original data is not
modified.  If False, the original data is modified, and put back before
the function returns, but small numerical differences may be introduced
by subtracting and then adding the data mean.</p>
</dd>
<dt><strong>n_jobs</strong><span class="classifier">int</span></dt><dd><p>The number of jobs to use for the computation. This works by computing
each of the n_init runs in parallel.</p>
<p>If -1 all CPUs are used. If 1 is given, no parallel computing code is
used at all, which is useful for debugging. For n_jobs below -1,
(n_cpus + 1 + n_jobs) are used. Thus for n_jobs = -2, all CPUs but one
are used.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>K-means problem constrained with a minimum and/or maximum size for each cluster.</p>
<p>The constrained assignment is formulated as a Minimum Cost Flow (MCF) linear network optimisation
problem. This is then solved using a cost-scaling push-relabel algorithm. The implementation used is</p>
<blockquote>
<div><p>Google’s Operations Research tools’s <cite>SimpleMinCostFlow</cite>.</p>
</div></blockquote>
<p>Ref:
1. Bradley, P. S., K. P. Bennett, and Ayhan Demiriz. “Constrained k-means clustering.”</p>
<blockquote>
<div><p>Microsoft Research, Redmond (2000): 1-8.</p>
</div></blockquote>
<ol class="arabic simple" start="2">
<li><dl class="simple">
<dt>Google’s SimpleMinCostFlow implementation:</dt><dd><p><a class="reference external" href="https://github.com/google/or-tools/blob/master/ortools/graph/min_cost_flow.h">https://github.com/google/or-tools/blob/master/ortools/graph/min_cost_flow.h</a></p>
</dd>
</dl>
</li>
</ol>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">k_means_constrained</span> <span class="kn">import</span> <span class="n">KMeansConstrained</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">KMeansConstrained</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">size_min</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">size_max</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">labels_</span>
<span class="go">array([0, 0, 0, 1, 1, 1], dtype=int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="go">array([0, 1], dtype=int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">cluster_centers_</span>
<span class="go">array([[ 1.,  2.],</span>
<span class="go">       [ 4.,  2.]])</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Attributes</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>cluster_centers_</strong><span class="classifier">array, [n_clusters, n_features]</span></dt><dd><p>Coordinates of cluster centers</p>
</dd>
<dt><strong>labels_ :</strong></dt><dd><p>Labels of each point</p>
</dd>
<dt><strong>inertia_</strong><span class="classifier">float</span></dt><dd><p>Sum of squared distances of samples to their closest cluster center.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#k_means_constrained.KMeansConstrained.fit" title="k_means_constrained.KMeansConstrained.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(X[, y])</p></td>
<td><p>Compute k-means clustering with given constants.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#k_means_constrained.KMeansConstrained.fit_predict" title="k_means_constrained.KMeansConstrained.fit_predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit_predict</span></code></a>(X[, y])</p></td>
<td><p>Compute cluster centers and predict cluster index for each sample.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#k_means_constrained.KMeansConstrained.fit_transform" title="k_means_constrained.KMeansConstrained.fit_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit_transform</span></code></a>(X[, y])</p></td>
<td><p>Compute clustering and transform X to cluster-distance space.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#k_means_constrained.KMeansConstrained.get_params" title="k_means_constrained.KMeansConstrained.get_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code></a>([deep])</p></td>
<td><p>Get parameters for this estimator.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#k_means_constrained.KMeansConstrained.predict" title="k_means_constrained.KMeansConstrained.predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict</span></code></a>(X[, size_min, size_max])</p></td>
<td><p>Predict the closest cluster each sample in X belongs to given the provided constraints.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#k_means_constrained.KMeansConstrained.score" title="k_means_constrained.KMeansConstrained.score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">score</span></code></a>(X[, y])</p></td>
<td><p>Opposite of the value of X on the K-means objective.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#k_means_constrained.KMeansConstrained.set_params" title="k_means_constrained.KMeansConstrained.set_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code></a>(**params)</p></td>
<td><p>Set the parameters of this estimator.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#k_means_constrained.KMeansConstrained.transform" title="k_means_constrained.KMeansConstrained.transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transform</span></code></a>(X)</p></td>
<td><p>Transform X to a cluster-distance space.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt id="k_means_constrained.KMeansConstrained.fit">
<code class="sig-name descname">fit</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/k_means_constrained/k_means_constrained_.html#KMeansConstrained.fit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#k_means_constrained.KMeansConstrained.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute k-means clustering with given constants.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like, shape=(n_samples, n_features)</span></dt><dd><p>Training instances to cluster.</p>
</dd>
<dt><strong>y</strong><span class="classifier">Ignored</span></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="k_means_constrained.KMeansConstrained.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">size_min</span><span class="o">=</span><span class="default_value">'init'</span></em>, <em class="sig-param"><span class="n">size_max</span><span class="o">=</span><span class="default_value">'init'</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/k_means_constrained/k_means_constrained_.html#KMeansConstrained.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#k_means_constrained.KMeansConstrained.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the closest cluster each sample in X belongs to given the provided constraints.
The constraints can be temporally overridden when determining which cluster each datapoint is assigned to.</p>
<p>Only computes the assignment step. It does not re-fit the cluster positions.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like, shape = [n_samples, n_features]</span></dt><dd><p>New data to predict.</p>
</dd>
<dt><strong>size_min</strong><span class="classifier">int, optional, default: size_min provided with initialisation</span></dt><dd><p>Constrain the label assignment so that each cluster has a minimum
size of size_min. If None, no constrains will be applied.
If ‘init’ the value provided during initialisation of the
class will be used.</p>
</dd>
<dt><strong>size_max</strong><span class="classifier">int, optional, default: size_max provided with initialisation</span></dt><dd><p>Constrain the label assignment so that each cluster has a maximum
size of size_max. If None, no constrains will be applied.
If ‘init’ the value provided during initialisation of the
class will be used.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>labels</strong><span class="classifier">array, shape [n_samples,]</span></dt><dd><p>Index of the cluster each sample belongs to.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="k_means_constrained.KMeansConstrained.fit_predict">
<code class="sig-name descname">fit_predict</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#k_means_constrained.KMeansConstrained.fit_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute cluster centers and predict cluster index for each sample.</p>
<p>Convenience method; equivalent to calling fit(X) followed by
predict(X).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">{array-like, sparse matrix}, shape = [n_samples, n_features]</span></dt><dd><p>New data to transform.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>labels</strong><span class="classifier">array, shape [n_samples,]</span></dt><dd><p>Index of the cluster each sample belongs to.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="k_means_constrained.KMeansConstrained.fit_transform">
<code class="sig-name descname">fit_transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#k_means_constrained.KMeansConstrained.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute clustering and transform X to cluster-distance space.</p>
<p>Equivalent to fit(X).transform(X), but more efficiently implemented.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">{array-like, sparse matrix}, shape = [n_samples, n_features]</span></dt><dd><p>New data to transform.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>X_new</strong><span class="classifier">array, shape [n_samples, k]</span></dt><dd><p>X transformed in the new space.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="k_means_constrained.KMeansConstrained.get_params">
<code class="sig-name descname">get_params</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">deep</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span><a class="headerlink" href="#k_means_constrained.KMeansConstrained.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get parameters for this estimator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>deep</strong><span class="classifier">boolean, optional</span></dt><dd><p>If True, will return the parameters for this estimator and
contained subobjects that are estimators.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>params</strong><span class="classifier">mapping of string to any</span></dt><dd><p>Parameter names mapped to their values.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="k_means_constrained.KMeansConstrained.score">
<code class="sig-name descname">score</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em>, <em class="sig-param"><span class="n">y</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="headerlink" href="#k_means_constrained.KMeansConstrained.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Opposite of the value of X on the K-means objective.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">{array-like, sparse matrix}, shape = [n_samples, n_features]</span></dt><dd><p>New data.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>score</strong><span class="classifier">float</span></dt><dd><p>Opposite of the value of X on the K-means objective.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="k_means_constrained.KMeansConstrained.set_params">
<code class="sig-name descname">set_params</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">**</span><span class="n">params</span></em><span class="sig-paren">)</span><a class="headerlink" href="#k_means_constrained.KMeansConstrained.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the parameters of this estimator.</p>
<p>The method works on simple estimators as well as on nested objects
(such as pipelines). The latter have parameters of the form
<code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> so that it’s possible to update each
component of a nested object.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><dl class="simple">
<dt>self</dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="k_means_constrained.KMeansConstrained.transform">
<code class="sig-name descname">transform</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">X</span></em><span class="sig-paren">)</span><a class="headerlink" href="#k_means_constrained.KMeansConstrained.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform X to a cluster-distance space.</p>
<p>In the new space, each dimension is the distance to the cluster
centers.  Note that even if X is sparse, the array returned by
<cite>transform</cite> will typically be dense.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">{array-like, sparse matrix}, shape = [n_samples, n_features]</span></dt><dd><p>New data to transform.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>X_new</strong><span class="classifier">array, shape [n_samples, k]</span></dt><dd><p>X transformed in the new space.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2020, Josh Levy-Kramer. Documentation derived from Scikit-Learn

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>